{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# fuzzywuzzy module for text processing\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "import charset_normalizer\n",
    "\n",
    "# or jellyfish module\n",
    "import jellyfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from url\n",
    "\n",
    "url = \"https://storage.googleapis.com/kagglesdsdata/datasets/819513/1402182/pakistan_intellectual_capital.csv?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240422%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240422T081810Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=7908b20e129f445b1d707d1eb4d52c4c3f2b8abbe431d968495d2aa6e5a333397790d83090abe72f45682deba3879d0db77580f807199206aae30fb77d7353c3bb4e223610d0ce34283d1096ff36d441dbfd266193a27b45d6b649b588bf07c398940205218d0d4b4a0f53f77818c7e2480c1477eadc24ffb58b16d4fd2a7617e24966e7cf1f27a3cac1161e293f08f3e40ffce79c15db5366f942e1cf89bb34653015f85102acc767025829430d7b8a987ee6d061bd3b95d5a89d4cc72aeca495c47775f49e2db0e5907ab15edac05e8658fd5e1a8779465094586bb81733a8cbcdaca8e40bc9afa578767367f4bf10a69583e5699c1a54b6ab8176aec1cd75\"\n",
    "professors = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S#</th>\n",
       "      <th>Teacher Name</th>\n",
       "      <th>University Currently Teaching</th>\n",
       "      <th>Department</th>\n",
       "      <th>Province University Located</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Terminal Degree</th>\n",
       "      <th>Graduated from</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Area of Specialization/Research Interests</th>\n",
       "      <th>Other Information</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Dr. Abdul Basit</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software Engineering &amp; DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Dr. Waheed Noor</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DBMS</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Dr. Junaid Baber</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Information processing, Multimedia mining</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>Dr. Maheen Bakhtyar</td>\n",
       "      <td>University of Balochistan</td>\n",
       "      <td>Computer Science &amp; IT</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Asian Institute of Technology</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NLP, Information Retrieval, Question Answering...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>Samina Azim</td>\n",
       "      <td>Sardar Bahadur Khan Women's University</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>BS</td>\n",
       "      <td>Balochistan University of Information Technolo...</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>VLSI Electronics DLD Database</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>1974</td>\n",
       "      <td>1975</td>\n",
       "      <td>Dr. Ahmar Rashid</td>\n",
       "      <td>Ghulam Ishaq Khan Institute</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>JNU</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Electrical Impedance Tomography, Inverse algor...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>1975</td>\n",
       "      <td>1976</td>\n",
       "      <td>Dr. Fawad Hussain</td>\n",
       "      <td>Ghulam Ishaq Khan Institute</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Grenoble</td>\n",
       "      <td>France</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Machine Learning, Big Data Anaysis, Data Minin...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>1977</td>\n",
       "      <td>1978</td>\n",
       "      <td>Dr. Rashad M Jillani</td>\n",
       "      <td>Ghulam Ishaq Khan Institute</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Florida Atlantic University</td>\n",
       "      <td>USA</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Digital Multimedia Systems, Video Compression ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>1979</td>\n",
       "      <td>1980</td>\n",
       "      <td>Dr. Shahabuddin Ansari</td>\n",
       "      <td>Ghulam Ishaq Khan Institute</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Ghulam Ishaq Khan Institute of Science and Tec...</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medical Image Processing and Analysis, Digital...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>1980</td>\n",
       "      <td>1981</td>\n",
       "      <td>Dr. Sajid Anwar</td>\n",
       "      <td>Ghulam Ishaq Khan Institute</td>\n",
       "      <td>Computer Science and Engineering</td>\n",
       "      <td>KPK</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Seoul National University</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pruning and Quantizing CNN, GPGPU,</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1142 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    S#            Teacher Name  \\\n",
       "0              2     3         Dr. Abdul Basit   \n",
       "1              4     5         Dr. Waheed Noor   \n",
       "2              5     6        Dr. Junaid Baber   \n",
       "3              6     7     Dr. Maheen Bakhtyar   \n",
       "4             24    25             Samina Azim   \n",
       "...          ...   ...                     ...   \n",
       "1137        1974  1975        Dr. Ahmar Rashid   \n",
       "1138        1975  1976       Dr. Fawad Hussain   \n",
       "1139        1977  1978    Dr. Rashad M Jillani   \n",
       "1140        1979  1980  Dr. Shahabuddin Ansari   \n",
       "1141        1980  1981         Dr. Sajid Anwar   \n",
       "\n",
       "               University Currently Teaching  \\\n",
       "0                  University of Balochistan   \n",
       "1                  University of Balochistan   \n",
       "2                  University of Balochistan   \n",
       "3                  University of Balochistan   \n",
       "4     Sardar Bahadur Khan Women's University   \n",
       "...                                      ...   \n",
       "1137             Ghulam Ishaq Khan Institute   \n",
       "1138             Ghulam Ishaq Khan Institute   \n",
       "1139             Ghulam Ishaq Khan Institute   \n",
       "1140             Ghulam Ishaq Khan Institute   \n",
       "1141             Ghulam Ishaq Khan Institute   \n",
       "\n",
       "                            Department Province University Located  \\\n",
       "0                Computer Science & IT                 Balochistan   \n",
       "1                Computer Science & IT                 Balochistan   \n",
       "2                Computer Science & IT                 Balochistan   \n",
       "3                Computer Science & IT                 Balochistan   \n",
       "4                     Computer Science                 Balochistan   \n",
       "...                                ...                         ...   \n",
       "1137  Computer Science and Engineering                         KPK   \n",
       "1138  Computer Science and Engineering                         KPK   \n",
       "1139  Computer Science and Engineering                         KPK   \n",
       "1140  Computer Science and Engineering                         KPK   \n",
       "1141  Computer Science and Engineering                         KPK   \n",
       "\n",
       "              Designation Terminal Degree  \\\n",
       "0     Assistant Professor             PhD   \n",
       "1     Assistant Professor             PhD   \n",
       "2     Assistant Professor             PhD   \n",
       "3     Assistant Professor             PhD   \n",
       "4                Lecturer              BS   \n",
       "...                   ...             ...   \n",
       "1137  Associate Professor             PhD   \n",
       "1138  Associate Professor             PhD   \n",
       "1139  Assistant Professor             PhD   \n",
       "1140  Assistant Professor             PhD   \n",
       "1141  Assistant Professor             PhD   \n",
       "\n",
       "                                         Graduated from      Country    Year  \\\n",
       "0                         Asian Institute of Technology     Thailand     NaN   \n",
       "1                         Asian Institute of Technology     Thailand     NaN   \n",
       "2                         Asian Institute of Technology     Thailand     NaN   \n",
       "3                         Asian Institute of Technology     Thailand     NaN   \n",
       "4     Balochistan University of Information Technolo...     Pakistan  2005.0   \n",
       "...                                                 ...          ...     ...   \n",
       "1137                                                JNU  South Korea     NaN   \n",
       "1138                                           Grenoble       France     NaN   \n",
       "1139                        Florida Atlantic University          USA  2012.0   \n",
       "1140  Ghulam Ishaq Khan Institute of Science and Tec...     Pakistan     NaN   \n",
       "1141                          Seoul National University  South Korea     NaN   \n",
       "\n",
       "              Area of Specialization/Research Interests Other Information  \n",
       "0                           Software Engineering & DBMS               NaN  \n",
       "1                                                  DBMS               NaN  \n",
       "2             Information processing, Multimedia mining               NaN  \n",
       "3     NLP, Information Retrieval, Question Answering...               NaN  \n",
       "4                         VLSI Electronics DLD Database               NaN  \n",
       "...                                                 ...               ...  \n",
       "1137  Electrical Impedance Tomography, Inverse algor...               NaN  \n",
       "1138  Machine Learning, Big Data Anaysis, Data Minin...               NaN  \n",
       "1139  Digital Multimedia Systems, Video Compression ...               NaN  \n",
       "1140  Medical Image Processing and Analysis, Digital...               NaN  \n",
       "1141                 Pruning and Quantizing CNN, GPGPU,               NaN  \n",
       "\n",
       "[1142 rows x 13 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the table\n",
    "professors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some text pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Germany', ' New Zealand', ' Sweden', ' USA', 'Australia',\n",
       "       'Austria', 'Canada', 'China', 'Finland', 'France', 'Greece',\n",
       "       'HongKong', 'Ireland', 'Italy', 'Japan', 'Macau', 'Malaysia',\n",
       "       'Mauritius', 'Netherland', 'New Zealand', 'Norway', 'Pakistan',\n",
       "       'Portugal', 'Russian Federation', 'Saudi Arabia', 'Scotland',\n",
       "       'Singapore', 'South Korea', 'SouthKorea', 'Spain', 'Sweden',\n",
       "       'Thailand', 'Turkey', 'UK', 'USA', 'USofA', 'Urbana', 'germany'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at this, we can see some problems due to inconsistent data entry: ' Germany', and 'germany', for example, or ' New Zealand' and 'New Zealand'.\n",
    "\n",
    "The first thing to repair this errors: \n",
    "- make everything lower case\n",
    "- remove any white spaces at the beginning and end of cells. \n",
    "\n",
    "Inconsistencies in capitalizations and trailing white spaces are very common in text data and you can fix a good 80% of your text data entry inconsistencies by doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "professors['Country'] = professors['Country'].str.lower()\n",
    "# remove trailing white spaces\n",
    "professors['Country'] = professors['Country'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use more advanced methods to correct inconsistent text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea',\n",
       "       'southkorea', 'spain', 'sweden', 'thailand', 'turkey', 'uk',\n",
       "       'urbana', 'usa', 'usofa'], dtype=object)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does look like there is another inconsistency: 'southkorea' and 'south korea' should be the same.\n",
    "\n",
    "We can use two packages to help identify which strings are closest to each other. This is the fuzzywuzzy and the jellyfish libraries.\n",
    "\n",
    "This dataset is small enough that we could probably could correct errors by hand, but that approach doesn't scale well. (Would you want to correct a thousand errors by hand? What about ten thousand? Automating things as early as possible is generally a good idea.)\n",
    "\n",
    "The idea of these libraries:\n",
    "\n",
    "- Fuzzy matching: The process of automatically finding text strings that are very similar to the target string. In general, a string is considered \"closer\" to another one the fewer characters you'd need to change if you were transforming one string into another. So \"apple\" and \"snapple\" are two changes away from each other (add \"s\" and \"n\") while \"in\" and \"on\" and one change away (rplace \"i\" with \"o\"). You won't always be able to rely on fuzzy matching 100%, but it will usually end up saving you at least a little time.\n",
    "Fuzzywuzzy returns a ratio given two strings. The closer the ratio is to 100, the smaller the edit distance between the two strings. Here, we're going to get the ten strings from our list of cities that have the closest distance to \"south korea\".\n",
    "\n",
    "- Jaro distance: In computer science and statistics, the Jaroâ€“Winkler similarity is a string metric measuring an edit distance between two sequences. The higher the Jaroâ€“Winkler distance for two strings is, the less similar the strings are. The score is normalized such that 0 means an exact match and 1 means there is no similarity. The original paper actually defined the metric in terms of similarity, so the distance is defined as the inversion of that value (distance = 1 âˆ’ similarity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('south korea', 100),\n",
       " ('southkorea', 48),\n",
       " ('saudi arabia', 43),\n",
       " ('norway', 35),\n",
       " ('ireland', 33),\n",
       " ('portugal', 32),\n",
       " ('singapore', 30),\n",
       " ('netherland', 29),\n",
       " ('macau', 25),\n",
       " ('usofa', 25)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first, use the fuzzy matching:\n",
    "# get the top 10 closest matches to \"south korea\"\n",
    "matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "# check the results\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaro distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# then, use the jaro distance method:\n",
    "# lets check the similarity between texts manually for the first time\n",
    "jellyfish.jaro_similarity('south korea', 'southkorea')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the result is a much bigger number than it was in the fuzzy matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets make a function that iterate through a list of text to make it faster\n",
    "def jelly_sim_fun(ref_str, list_str):\n",
    "    sim = []\n",
    "    for x in list_str:\n",
    "        sim.append(jellyfish.jaro_similarity(ref_str, x))\n",
    "    return pd.concat([pd.Series(sim), pd.Series(list_str)], axis=1, ignore_index=True).rename(columns={0:'similarity',1:'names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>south korea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.969697</td>\n",
       "      <td>southkorea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.656277</td>\n",
       "      <td>austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.603367</td>\n",
       "      <td>australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.602694</td>\n",
       "      <td>singapore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.587879</td>\n",
       "      <td>netherland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.557071</td>\n",
       "      <td>saudi arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.549242</td>\n",
       "      <td>scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.537879</td>\n",
       "      <td>hongkong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.537879</td>\n",
       "      <td>portugal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    similarity         names\n",
       "24    1.000000   south korea\n",
       "25    0.969697    southkorea\n",
       "1     0.656277       austria\n",
       "0     0.603367     australia\n",
       "23    0.602694     singapore\n",
       "15    0.587879    netherland\n",
       "21    0.557071  saudi arabia\n",
       "22    0.549242      scotland\n",
       "8     0.537879      hongkong\n",
       "19    0.537879      portugal"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see the more similar texts according to jaro distances\n",
    "jelly_sim_fun(ref_str= 'south korea', list_str= countries).sort_values(by='similarity', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the result is clearer than in the previous case, with a larger difference between the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the inconsistent texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that two of the items in the cities are very close to \"south korea\": \"south korea\" and \"southkorea\". \n",
    "\n",
    "Let's replace all rows in our \"Country\" column that have a ratio of > 0.9 with \"south korea\", so now we will use the jaro distance method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to replace rows in the provided column of the provided dataframe\n",
    "# that match the provided string above the provided ratio with the provided string\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 0.9):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    matches = jelly_sim_fun(ref_str= string_to_match, list_str= strings).values.tolist()\n",
    "\n",
    "    # only get matches with a ratio > 0.9\n",
    "    close_matches = [matches[1] for matches in matches if matches[0] >= min_ratio]\n",
    "\n",
    "    # get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function we just wrote to replace close matches to \"south korea\" with \"south korea\"\n",
    "replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['australia', 'austria', 'canada', 'china', 'finland', 'france',\n",
       "       'germany', 'greece', 'hongkong', 'ireland', 'italy', 'japan',\n",
       "       'macau', 'malaysia', 'mauritius', 'netherland', 'new zealand',\n",
       "       'norway', 'pakistan', 'portugal', 'russian federation',\n",
       "       'saudi arabia', 'scotland', 'singapore', 'south korea', 'spain',\n",
       "       'sweden', 'thailand', 'turkey', 'uk', 'urbana', 'usa', 'usofa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results\n",
    "\n",
    "# get all the unique values in the 'Country' column\n",
    "countries = professors['Country'].unique()\n",
    "\n",
    "# sort them alphabetically and then take a closer look\n",
    "countries.sort()\n",
    "countries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
